#### Custom Configuration - Ollama

**Use RAG with Ollama Local Embedding**

**Prerequisite:** You need Ollama and the `nomic-embed-text` embedding model:

- `ollama pull nomic-embed-text`

1. Add the following to your `.env` file:

    ```sh
    RAG_API_URL=http://host.docker.internal:8000
    EMBEDDINGS_PROVIDER=ollama
    OLLAMA_BASE_URL=http://host.docker.internal:11434
    EMBEDDINGS_MODEL=nomic-embed-text
    ```

2. Update your `docker-compose.override.yml` file with:

    ```yaml
    version: '3.4'

    services:
      rag_api:
        image: ghcr.io/danny-avila/librechat-rag-api-dev:latest
        # If running on Linux
        # extra_hosts:
        #   - "host.docker.internal:host-gateway"
    ```

3. Run the command to start the Docker containers:

    ```sh
    docker compose up -d
    ```

That's it!